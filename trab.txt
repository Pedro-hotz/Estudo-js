-- apresenta√ß√£o 

Projeto: Previs√£o de Pre√ßos de Im√≥veis Urbanos

O mercado imobili√°rio sempre despertou grande interesse por ser um dos setores mais din√¢micos e influenciados por m√∫ltiplos fatores sociais, geogr√°ficos e econ√¥micos. Ao observar esse cen√°rio, surgiu a seguinte pergunta central para este trabalho:

‚ÄúComo prever o pre√ßo de venda de um im√≥vel urbano a partir de caracter√≠sticas f√≠sicas e de localiza√ß√£o?‚Äù

Essa pergunta √© extremamente relevante, pois o valor de um im√≥vel n√£o depende apenas das suas dimens√µes, mas tamb√©m de fatores como localiza√ß√£o, renda m√©dia da regi√£o, proximidade ao oceano, densidade populacional e idade das constru√ß√µes. Entender como esses fatores influenciam o pre√ßo abre espa√ßo para an√°lises importantes no planejamento urbano, avalia√ß√£o imobili√°ria, investimentos e at√© pol√≠ticas p√∫blicas.

-------





--- Introdu√ß√£o

Para este projeto, escolhemos analisar a base de dados California Housing, um dataset amplamente utilizado em estudos de precifica√ß√£o imobili√°ria. Essa base cont√©m informa√ß√µes sobre im√≥veis localizados na Calif√≥rnia, incluindo caracter√≠sticas f√≠sicas das casas, informa√ß√µes socioecon√¥micas dos arredores e dados geogr√°ficos como latitude, longitude e proximidade com o oceano.

Nosso objetivo √© desenvolver um modelo capaz de responder √† pergunta:

"Como prever o pre√ßo de venda de um im√≥vel urbano a partir de caracter√≠sticas f√≠sicas e de localiza√ß√£o?"

Essa an√°lise √© extremamente relevante, pois o mercado imobili√°rio √© influenciado por diversos fatores, e entender o peso de cada vari√°vel pode ajudar compradores, vendedores e analistas a tomar decis√µes mais precisas. Al√©m disso, trabalhar com esse dataset nos permite aplicar t√©cnicas reais de ci√™ncia de dados e machine learning.

lib 
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns

    # pr√©-processamento, modelos e metricas 
    from sklearn.datasets import fetch_california_housing
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    from sklearn.linear_model import LinearRegression
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

----------------------------------------




--- DESENVOLVIMENTO
1. Descri√ß√£o da Base de Dados

Para este projeto, utilizamos o California Housing Dataset, um conjunto de dados criado com informa√ß√µes do censo dos Estados Unidos. Esse dataset √© comumente usado para problemas de regress√£o envolvendo pre√ßos de im√≥veis. Ele representa caracter√≠sticas f√≠sicas, socioecon√¥micas e geogr√°ficas das regi√µes da Calif√≥rnia.

A base cont√©m aproximadamente 20.640 registros e 10 vari√°veis. Dentre essas vari√°veis, 9 s√£o explicativas e apenas uma √© a vari√°vel alvo, respons√°vel por representar o pre√ßo do im√≥vel (median_house_value).

Vari√°veis presentes:

longitude ‚Äì coordenada geogr√°fica (Leste/Oeste)

latitude ‚Äì coordenada geogr√°fica (Norte/Sul)

housing_median_age ‚Äì idade m√©dia das casas

total_rooms ‚Äì total de c√¥modos

total_bedrooms ‚Äì total de quartos

population ‚Äì popula√ß√£o da regi√£o

households ‚Äì n√∫mero de domic√≠lios

median_income ‚Äì renda mediana da regi√£o

ocean_proximity ‚Äì proximidade ao oceano (vari√°vel categ√≥rica)

median_house_value ‚Äì valor mediano das resid√™ncias (vari√°vel alvo)

A escolha desse dataset se justifica porque ele √© clean, bem estruturado, amplamente utilizado em Machine Learning e permite uma an√°lise consistente da pergunta central deste projeto:
‚ÄúComo prever o pre√ßo de venda de um im√≥vel urbano a partir de caracter√≠sticas f√≠sicas e de localiza√ß√£o?‚Äù

2. An√°lise Explorat√≥ria de Dados (AED)

Antes de criar qualquer modelo de machine learning, foi realizada uma An√°lise Explorat√≥ria de Dados para entender o comportamento das vari√°veis e identificar padr√µes relevantes.

Ao examinar a vari√°vel alvo, observou-se uma distribui√ß√£o levemente assim√©trica, com presen√ßa de valores mais altos que puxam a cauda da distribui√ß√£o. Isso indica que a Calif√≥rnia possui regi√µes com pre√ßos acima do padr√£o.

A an√°lise de correla√ß√£o mostrou que a vari√°vel mais relacionada ao pre√ßo √© a renda mediana (median_income). Quanto maior a renda da popula√ß√£o local, maior tende a ser o valor dos im√≥veis. Al√©m disso, vari√°veis geogr√°ficas como latitude e longitude tamb√©m t√™m correla√ß√£o significativa, sugerindo que localiza√ß√£o √© um fator importante.

Gr√°ficos de dispers√£o refor√ßaram a rela√ß√£o positiva entre renda e pre√ßo, demonstrando uma tend√™ncia clara: regi√µes mais ricas possuem im√≥veis mais valorizados.

Tamb√©m foi avaliado o comportamento das vari√°veis demogr√°ficas, como popula√ß√£o, n√∫mero de quartos e n√∫mero de domic√≠lios. Observou-se que essas vari√°veis possuem comportamentos mais espalhados, n√£o apresentando correla√ß√µes t√£o fortes quanto renda ou localiza√ß√£o.

3. Prepara√ß√£o dos Dados

Ap√≥s a explora√ß√£o inicial, iniciou-se o processo de prepara√ß√£o dos dados para torn√°-los adequados aos modelos de Machine Learning.

Tratamento de valores ausentes

Foi identificado que a vari√°vel total_bedrooms possu√≠a valores faltantes. Para manter consist√™ncia e evitar distor√ß√µes, esses valores foram substitu√≠dos pela mediana, garantindo estabilidade estat√≠stica.

Transforma√ß√£o de vari√°veis categ√≥ricas

A vari√°vel ocean_proximity √© categ√≥rica. Para transform√°-la em um formato num√©rico compat√≠vel com os algoritmos, aplicou-se One-Hot Encoding, criando colunas bin√°rias que representam cada categoria.

Separa√ß√£o entre vari√°veis independentes e dependentes

A vari√°vel alvo (median_house_value) foi separada das vari√°veis explicativas. Isso permitiu preparar corretamente o conjunto para o treinamento dos modelos.

Divis√£o entre treino e teste

Os dados foram divididos em 80% para treino e 20% para teste. Essa abordagem garante que o modelo aprenda com uma parte da base e seja avaliado com outra parte nunca vista antes, simulando um cen√°rio real de previs√£o.

Normaliza√ß√£o

As vari√°veis num√©ricas foram padronizadas utilizando normaliza√ß√£o estat√≠stica (m√©dia 0 e desvio padr√£o 1). Essa etapa √© fundamental para algoritmos que dependem da escala dos dados, como regress√£o linear.

Com esses passos conclu√≠dos, os dados estavam devidamente organizados, limpos e prontos para a etapa de modelagem.


--------------------------




---- ALGORITMOS E METODOLOGIA
1. Algoritmos Utilizados

Para responder √† pergunta ‚ÄúComo prever o pre√ßo de venda de um im√≥vel urbano a partir de caracter√≠sticas f√≠sicas e de localiza√ß√£o?‚Äù, utilizamos dois algoritmos de Machine Learning amplamente adotados em problemas de regress√£o:

üìå 1.1 Regress√£o Linear

A Regress√£o Linear √© um dos modelos mais tradicionais e simples para problemas de previs√£o num√©rica.
Ela tenta encontrar uma linha (ou hiperplano) que melhor se ajusta aos dados, minimizando o erro entre previs√µes e valores reais.

Por que usar esse algoritmo?

Serve como um √≥timo ponto de partida (baseline).

F√°cil de interpretar.

√â leve e r√°pido de treinar.

No c√≥digo (comentado no notebook), fizemos:

Importa√ß√£o da classe LinearRegression.

Treinamento do modelo com os dados normalizados.

Predi√ß√µes sobre o conjunto de teste.

C√°lculo das m√©tricas RMSE, MAE e R¬≤.

üìå 1.2 Random Forest Regressor

O Random Forest √© um modelo baseado em √°rvores de decis√£o que combina diversas √°rvores para aumentar a precis√£o e reduzir o risco de overfitting.

Por que usar esse algoritmo?

Captura rela√ß√µes n√£o lineares.

Funciona muito bem com dados tabulares.

√â robusto e possui alta capacidade de generaliza√ß√£o.

No notebook, o modelo realizou:

Cria√ß√£o do regressor com n√∫mero padr√£o de √°rvores.

Treinamento sobre o mesmo conjunto de dados da regress√£o linear.

Predi√ß√µes sobre o conjunto de teste.

Avalia√ß√£o usando as mesmas m√©tricas.

Al√©m disso, o Random Forest permitiu extrair a import√¢ncia das vari√°veis, mostrando quais fatores mais influenciam o pre√ßo dos im√≥veis ‚Äî informa√ß√£o utilizada para gerar um gr√°fico no notebook.

2. Metodologia Aplicada

A metodologia adotada seguiu as etapas cl√°ssicas de um pipeline de Machine Learning:

üîπ 2.1 Coleta e carregamento dos dados

A base California Housing foi carregada diretamente via biblioteca Scikit-Learn, evitando downloads externos.

üîπ 2.2 An√°lise Explorat√≥ria de Dados (AED)

Incluiu:

inspe√ß√£o da distribui√ß√£o da vari√°vel alvo,

an√°lise de correla√ß√£o,

visualiza√ß√µes gr√°ficas,

busca por padr√µes geogr√°ficos,

identifica√ß√£o de vari√°veis mais relevantes.

üîπ 2.3 Prepara√ß√£o dos Dados

Etapas aplicadas:

tratamento de valores ausentes com mediana,

padroniza√ß√£o dos atributos num√©ricos,

convers√£o da vari√°vel categ√≥rica com One-Hot Encoding,

separa√ß√£o entre treino e teste,

montagem de um ColumnTransformer para automatizar todo o pr√©-processamento.

üîπ 2.4 Treinamento dos Modelos

Ambos os modelos (Linear Regression e Random Forest) foram treinados com os mesmos dados pr√©-processados.

üîπ 2.5 Avalia√ß√£o

Utilizamos tr√™s m√©tricas:

RMSE (Root Mean Squared Error) ‚Äî mede o erro m√©dio da previs√£o.

MAE (Mean Absolute Error) ‚Äî mede o erro m√©dio absoluto.

R¬≤ ‚Äî indica o quanto o modelo explica da varia√ß√£o dos dados.

üîπ 2.6 Interpreta√ß√£o

O Random Forest permitiu analisar as import√¢ncias das vari√°veis, concluindo que:

median_income √© a vari√°vel mais influente,

localiza√ß√£o (longitude/latitude) tamb√©m exerce forte peso,

caracter√≠sticas estruturais possuem influ√™ncia menor
----------------------------





--- CONCLUS√ÉO (para arquivo TXT)

O objetivo principal deste trabalho foi responder √† pergunta:

‚ÄúComo prever o pre√ßo de venda de um im√≥vel urbano a partir de caracter√≠sticas f√≠sicas e de localiza√ß√£o?‚Äù

Com base no California Housing Dataset e nos modelos aplicados, chegamos √†s seguintes conclus√µes:

A renda m√©dia da regi√£o √© o maior determinante do pre√ßo de um im√≥vel.
Ela apresentou a correla√ß√£o mais forte e, segundo o Random Forest, √© a vari√°vel mais importante do conjunto.

Localiza√ß√£o geogr√°fica tamb√©m tem forte influ√™ncia.
Latitude e longitude mostraram padr√µes claros, indicando valoriza√ß√£o em √°reas espec√≠ficas.

Modelos simples j√° fornecem bons resultados.
A Regress√£o Linear desempenhou bem, servindo como baseline s√≥lido.

Modelos mais complexos capturam melhor padr√µes n√£o lineares.
O Random Forest apresentou m√©tricas superiores e explicou melhor a varia√ß√£o dos dados.

A pergunta inicial foi respondida de forma satisfat√≥ria.
Mostramos que √© poss√≠vel prever pre√ßos de im√≥veis com base nas caracter√≠sticas escolhidas, alcan√ßando erros relativamente baixos e boa capacidade de generaliza√ß√£o.

Este estudo refor√ßa a import√¢ncia de fatores socioecon√¥micos e geogr√°ficos no mercado imobili√°rio e evidencia o potencial do Machine Learning para auxiliar em decis√µes desse setor.


--------------------------

--- REFER√äNCIAS (para arquivo TXT)
Bibliotecas e Documenta√ß√µes

Scikit-Learn Documentation ‚Äî https://scikit-learn.org/

Pandas Documentation ‚Äî https://pandas.pydata.org/

Matplotlib Documentation ‚Äî https://matplotlib.org/

Seaborn Documentation ‚Äî https://seaborn.pydata.org/

Bases de Dados

California Housing Dataset
Dispon√≠vel via sklearn.datasets.fetch_california_housing

Livros

G√©ron, Aur√©lien. Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow. 2nd edition. O‚ÄôReilly Media.

Bishop, C. M. Pattern Recognition and Machine Learning. Springer.

Artigos Cient√≠ficos

Pace, R. Kelley; Barry, Ronald. ‚ÄúSparse Spatial Autoregressions.‚Äù Statistics & Probability Letters, 1997.

Breiman, Leo. ‚ÄúRandom Forests.‚Äù Machine Learning, 2001.

Blogs e Materiais de Apoio

Towards Data Science ‚Äî artigos sobre regress√£o e Random Forest.

Kaggle Learn ‚Äî cursos de introdu√ß√£o a Machine Learning.

Uso de LLM

Durante a elabora√ß√£o deste projeto, parte dos c√≥digos, textos explicativos e estrutura√ß√£o metodol√≥gica foram realizados com aux√≠lio da LLM ChatGPT, incluindo:


aux√≠lio na organiza√ß√£o do pipeline,

sugest√µes de modelagem,

explica√ß√µes metodol√≥gicas,

formata√ß√£o final das se√ß√µes textuais.

------------------------------


============= C√ìDIGO =============== 

# importa as libs

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# pr√©-processamento, modelos e metricas 
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

---------------------

# Baixa o dataset do California housing

data = fetch_california_housing(as_frame=True)
df = data.frame.copy()

# muda target para "SalePrice"
df.rename(columns={"MedHouseVal": "SalePrice"}, inplace=True)

df.head()


----------------------


# Apenas exibe como os dados est√£o sendo distribu√≠dos 
# Ajuda a entender como os dados est√£o estruturados

print("Colunas:", df.columns.tolist())
print("\nShape:", df.shape)

df.describe()


-------------------


# Separa 20% para teste e o resto para treino
# teste avalia o desempenho
# treino √© para usar treinar os modelos 

X = df.drop(columns=["SalePrice"])
y = df["SalePrice"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


----------------------


# Padroniza√ß√£o dos dados

num_features = X.select_dtypes(include=['float64', 'int']).columns.tolist()
cat_features = []

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_features)
], remainder='passthrough')



-------------------


# Treina os modelos (antes do Pr√©-processamento)

# Regress√£o Linear
lin_model = Pipeline([
    ('prep', preprocessor),
    ('model', LinearRegression())
])

lin_model.fit(X_train, y_train)

# Random Forest
rf_model = Pipeline([
    ('prep', preprocessor),
    ('model', RandomForestRegressor(n_estimators=300, random_state=42))
])

rf_model.fit(X_train, y_train)


-------------------


# Mostra o resultado de desempenho de cada modelo 

def evaluate(model):
    pred = model.predict(X_test)
    return {
        "RMSE": np.sqrt(mean_squared_error(y_test, pred)),
        "MAE": mean_absolute_error(y_test, pred),
        "R2": r2_score(y_test, pred)
    }

results = pd.DataFrame({
    "Modelo": ["Linear Regression", "Random Forest"],
    "RMSE": [evaluate(lin_model)["RMSE"], evaluate(rf_model)["RMSE"]],
    "MAE": [evaluate(lin_model)["MAE"], evaluate(rf_model)["MAE"]],
    "R2": [evaluate(lin_model)["R2"], evaluate(rf_model)["R2"]],
})

results


-------------------

# Mostra os fatores mais importantes para o pre√ßo do imovel 

rf_regressor = rf_model.named_steps['model']
importances = rf_regressor.feature_importances_
feature_names = num_features

plt.figure(figsize=(10, 6))
plt.barh(feature_names, importances)
plt.title("Import√¢ncia das Caracter√≠sticas na Previs√£o do Pre√ßo do Im√≥vel")
plt.xlabel("Import√¢ncia")
plt.ylabel("Caracter√≠stica")
plt.show()


----------------------

# Vari√°veis = os atributos que descrevem cada im√≥vel
# As correla√ß√µes fortes indicam rela√ß√µes fortes importantes para o modelo

plt.figure(figsize=(10, 7))
sns.heatmap(df.corr(), annot=False, cmap="viridis")
plt.title("Mapa de Correla√ß√£o das Vari√°veis")
plt.show()


-----------------

y_pred = rf_model.predict(X_test)

plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred, alpha=0.3)
plt.xlabel("Valor Real")
plt.ylabel("Valor Predito")
plt.title("Compara√ß√£o: Valor Real vs. Predito")
plt.show()


----------------

